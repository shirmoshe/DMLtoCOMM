{
  "parallelism": {
    "data_parallel_size": 4,
    "pipeline_parallel_size": 2,
    "tensor_parallel_size": 3
  },
  "topology": {
    "__comment": "type can be: full_mesh, fat_tree",
    "type": "full_mesh",
    "num_gpus": 24,
    "link_latency_ms": 0,
    "bandwidth_gbps": 0
  },
  "hardware": {
    "gpus": []
  },
  "model": {
    "onnx_path": "",
    "data_size": 100
  }
}