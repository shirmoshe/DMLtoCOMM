{
  "visualization": {
    "show_config_tree": [0, 0, 0]
  },
  "topology": {
    "__comment": "type can be: full_mesh, fat_tree",
    "type": "full_mesh",
    "total_gpu": 24,
    "link_latency_ms": 0,
    "bandwidth_gbps": 10000000000
  },
  "hardware": {
    "gpus": [],
    "flop_rate": 1000000000000
  },
  "model": {
    "onnx_path": "load_model/tiny_llama_model/tiny_llama.onnx",
    "data_size": 100
  },
  "training": {
    "dataset_size": 64000,
    "global_batch_size": 64,
    "micro_batches_per_batch": 4
  }
}
